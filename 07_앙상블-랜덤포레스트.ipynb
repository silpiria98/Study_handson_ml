{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __1. 앙상블__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.ensanble`  \n",
    "<b>앙상블</b>은 여러개의 모델을 통해 최선의 결과를 도출하는 방법입니다.  \n",
    "일반적으로 단일의 모델이 보다 앙상블을 통해 나온 결과가 좋은 경우가 많습니다. \n",
    "> 편향은 비슷하지만, 분산이 줄어드는 경향이 있습니다.  \n",
    "\n",
    "### __1.1 직접/간접 투표__\n",
    "<b>직접투표</b><span style=\"font-size:70%\">hard voting</span>는 여러 모델의 값을 가지고 다수결로 최종 값을 정하는 것입니다.  \n",
    "\n",
    "보통 앙상블에 포함된 가장 우수한 모델보다 성능이 좋으며,  \n",
    "각각의 모델이 성능이 안좋아도 앙상블 모델은 좋은 성능을 보일 수 있습니다.  \n",
    "> 통계학의 <b>대수의 법칙</b>에 따라 모델(시행)이 많을 수록 정답(모수)과 가까워지는 성질 때문입니다.  \n",
    "  모든 시행이 독립적을 때의 얘기이므로 앙상블의 모델이 각기 독립적일수록 좋습니다.  \n",
    "  훈련 데이터를 다르게 하거나, 다른 알고리즘을 사용하면 됩니다.  \n",
    "\n",
    "<b>간접투표</b><span style=\"font-size:70%\">soft voting</span>는 평균으로 값을 정합니다.  \n",
    "회귀에 적합하며, 분류의 경우에도 모델이 확률값을 가지면 직접투표보다 성능이 좋은 경우가 있습니다.  \n",
    "\n",
    "\n",
    "### __1.2 앙상블 방법__\n",
    "<b>배깅</b>은 중복을 허용하여 전체 데이터중 일부를 랜덤추출로 사용하며,  \n",
    "<b>페이스팅</b>은 중복을 하지 않습니다.  \n",
    "> 배깅은 중복데이터로 편향이 늘지만(비독립적), 분산을 더욱 감소시켜 일반적으로 선호됩니다.  \n",
    "\n",
    "<b>부트스트랩</b>은 여러 모델을 병렬적으로 처리하는걸 의미합니다.  \n",
    "\n",
    "\n",
    "## __1.3 특성 앙상블__\n",
    "샘플이 아닌 특성을 일부만 사용하여 모델을 만들기도 합니다.  \n",
    "주로 이미지 등의 특성이 매우 많은 경우에 좋습니다.  \n",
    "> 분산이 줄지만, 특성 앙상블은 편향이 늘어납니다.  \n",
    "\n",
    "<b>랜덤패치 방식</b>은 샘플과 특성 모두 일부만 사용하는 방식이며,  \n",
    "<b>랜덤 서브스페이스 방식</b>은 전체 샘플을 사용하며 특성만 일부분 샘플링합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __2. 랜덤 포레스트__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결정트리를 여러개 만들어 앙상블 하는 방법입니다.  \n",
    "`skleanr.ensemble.RandomForest-`은 배깅을 사용하여 구현합니다.  \n",
    "또한, 각 노드에서 사용하는 특성이 불순도를 얼마나 낮추는지 확인하여 특성들의 중요도를 측정할 수 있습니다.  \n",
    "> `_.feature_importances_`  \n",
    " 일반 결정트리는 사용하는 몇 특성의 중요도만 나오지만, 랜덤포레스트는 모든 특성의 중요도가 보다 정확하게 측정됩니다.\n",
    "\n",
    "* __엑스트라 트리(익스트림 랜덤 트리)__  \n",
    " 어차피 많은 트리가 만들어지기 때문에, 처음부터 각 트리의 노드에서 최적의 임계값을 찾는게 아닌  \n",
    " 무작위 값으로 분할을 하는 방식입니다.  \n",
    " 트리에서 임계값을 찾는게 오래걸리기 때문에 이 방법이 빠르고, 랜덤 포레스트와의 성능은 비교를 해봐야 합니다.  \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __3. 부스팅__\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약한 학습기 여러개를 순차적으로 사용하여 점점 성능을 보완하는 방법입니다.  \n",
    "\n",
    "### __3.1 AdaBoost,__ (Adaptive-)  \n",
    "이전 모델에서 과소적합했던(잘못된) 샘플에 가중치를 높여 다음 모델을 개선합니다.  \n",
    "개선된 최종 모델을 사용하는 것이 아닌 앙상블을 하지만, 각 모델별 성능이 높을수록 가중치를 높게 주어 최종 값을 계산합니다.  \n",
    "\n",
    "* __학습 알고리즘__  \n",
    "각 샘플의 초기 가중치 $w_0$은 $1\\over m$으로, 아래의 식대로 계산합니다.  \n",
    "$w_{i+1}=\\begin{cases} w_i & \\hat{y_i}=y_i \\\\ w_{i} exp(\\alpha) & \\hat{y_i} \\neq y_i \\end{cases}$  \n",
    "모델 가중치, $\\alpha = \\eta log {1-r \\over r}$  \n",
    "에러율, $r={\\sum{w_i} (\\hat{y_i} \\neq y_i) \\over \\sum{w_i}}$  \n",
    "실제값과 예측값이 다른 샘플이 많을수록 모델 가중치가 적어집니다.   \n",
    "\n",
    "* __예측 알고리즘__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "704561b0d644309cd2ab0220a5b729490d45ccecc249cd05cdfebaf802484c8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
